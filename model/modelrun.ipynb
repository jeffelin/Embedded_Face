{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the Model\n",
    "\n",
    "From Shiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'NAME.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 64\u001b[0m\n\u001b[0;32m     59\u001b[0m \tspec \u001b[38;5;241m=\u001b[39m TN \u001b[38;5;241m/\u001b[39m (TN \u001b[38;5;241m+\u001b[39m FP)\n\u001b[0;32m     60\u001b[0m \t\u001b[38;5;28;01mreturn\u001b[39;00m spec\n\u001b[1;32m---> 64\u001b[0m dataset \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNAME.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)) \u001b[38;5;66;03m# dataset of confidence levels\u001b[39;00m\n\u001b[0;32m     65\u001b[0m target_data \u001b[38;5;241m=\u001b[39m dataset[:, \u001b[38;5;241m5\u001b[39m] \u001b[38;5;66;03m# UPDATE!\u001b[39;00m\n\u001b[0;32m     66\u001b[0m num_entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataset)\n",
      "File \u001b[1;32mc:\\Users\\jeffe\\anaconda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\jeffe\\anaconda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\jeffe\\anaconda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32mc:\\Users\\jeffe\\anaconda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\jeffe\\anaconda\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'NAME.csv'"
     ]
    }
   ],
   "source": [
    "#Face Model\n",
    "import csv # for reading the csv file\n",
    "import pandas as pd # uses dataframes from pandas\n",
    "import numpy as np # used for arrays\n",
    "from sklearn.ensemble import RandomForestClassifier # used for creating FSS score predictors --> Random Forest algorithm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold # for implementing k-folds\n",
    "import matplotlib.pyplot as plt # used for plotting the graphs\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "# FUNCTIONS:\n",
    "\n",
    "def create_conf_matrix(y_preds, y_reals):\n",
    "\tTP = 0\n",
    "\tFN = 0\n",
    "\tFP = 0\n",
    "\tTN = 0\n",
    "\tfalsePos = []\n",
    "\tfalseNeg = []\n",
    "\n",
    "\tfor i in range(len(y_preds)):\n",
    "\t\tpred_val = y_preds[i]\n",
    "\t\ttest_val = y_reals[i]\n",
    "\n",
    "\t\tif test_val == 1 and pred_val == 1:\n",
    "\t\t\tTP += 1\n",
    "\t\tif test_val == 1 and pred_val == 0:\n",
    "\t\t\tFN += 1\n",
    "\t\t\tfalseNeg.append(files[i])\n",
    "\t\tif test_val == 0 and pred_val == 1:\n",
    "\t\t\tFP += 1\n",
    "\t\t\tfalsePos.append(files[i])\n",
    "\t\tif test_val == 0 and pred_val == 0:\n",
    "\t\t\tTN += 1\n",
    "\n",
    "\tfalsePos.sort()\n",
    "\tfalseNeg.sort()\n",
    "\treturn [TP, FN, FP, TN]\n",
    "\n",
    "# calculates accuracy of model results\n",
    "def accuracy(matrix):\n",
    "\tTP = matrix[0]\n",
    "\tTN = matrix[3]\n",
    "\tacc = (TP + TN) / (matrix[0] + matrix[1] + matrix[2] + matrix[3])\n",
    "\treturn acc\n",
    "\n",
    "# calculates the sensitivity of model results\n",
    "def sensitivity(matrix):\n",
    "\tTP = matrix[0]\n",
    "\tFN = matrix[1]\n",
    "\tsens = TP / (TP + FN)\n",
    "\treturn sens\n",
    "\n",
    "# calculates the specificity of model results\n",
    "def specificity(matrix):\n",
    "\tTN = matrix[3]\n",
    "\tFP = matrix[2]\n",
    "\tspec = TN / (TN + FP)\n",
    "\treturn spec\n",
    "\n",
    "\n",
    "\n",
    "dataset = np.array(pd.read_csv('NAME.csv')) # dataset of confidence levels\n",
    "target_data = dataset[:, 5] # UPDATE!\n",
    "num_entries = len(dataset)\n",
    "\n",
    "labels = [\"ID\", \"CONF\"] # UPDATE COLUMN TITLES\n",
    "classes = [\"0\", \"1\"]\n",
    "\n",
    "kfold = KFold(n_splits = 10, shuffle = True, random_state = 100) # creates 10-fold splits\n",
    "face_preds = []\n",
    "face_truths = []\n",
    "\n",
    "for train_index, test_index in kfold.split(dataset):\n",
    "\n",
    "\tx_train, x_test = dataset[train_index], dataset[test_index]\n",
    "\ty_train, y_test = target_data[train_index], target_data[test_index]\n",
    "\n",
    "\tclassifier = RandomForestClassifier(max_depth = 6, min_samples_leaf = 3, min_samples_split = 10, class_weight = 'balanced', bootstrap = False, max_features = \"auto\", random_state = 100) # generates random forest model\n",
    "\tclassifier.fit(x_train, y_train) # trains the model using the training sets\n",
    "\ty_pred = classifier.predict(x_test) # predicts the data for the test dataset\n",
    "\t\n",
    "\tfor i in range(len(y_pred)):\n",
    "\t\tface_preds.append(y_pred[i])\n",
    "\t\tface_truths.append(y_test[i])\n",
    "\n",
    "\n",
    "matrix = create_conf_matrix(face_preds, face_truths, filePreds)\n",
    "print(\"[TP, FN, FP, TN] = \", end = \"\")\n",
    "print(matrix)\n",
    "print(\"\\nAccuracy: \" + str(accuracy(matrix)))\n",
    "print(\"Sensitivity: \" + str(sensitivity(matrix)))\n",
    "print(\"Specificity: \" + str(specificity(matrix)) + \"\\n\")\n",
    "\n",
    "# fig, axes = plt.subplots(nrows = 1, ncols = 1, figsize = (35, 10), dpi = 400)\n",
    "# tree.plot_tree(classifier.estimators_[0], feature_names = labels, class_names = classes, filled = True, impurity = False, precision = 1, fontsize = 10)\n",
    "# fig.savefig('decisionTree.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'modelData.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 75\u001b[0m\n\u001b[0;32m     70\u001b[0m \t\u001b[38;5;28;01mreturn\u001b[39;00m spec\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# MAIN:\u001b[39;00m\n\u001b[1;32m---> 75\u001b[0m dataset \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodelData.csv\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     76\u001b[0m target_data \u001b[38;5;241m=\u001b[39m dataset[:, \u001b[38;5;241m5\u001b[39m] \u001b[38;5;66;03m# UPDATE\u001b[39;00m\n\u001b[0;32m     77\u001b[0m num_entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataset)\n",
      "File \u001b[1;32mc:\\Users\\jeffe\\anaconda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\jeffe\\anaconda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\jeffe\\anaconda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32mc:\\Users\\jeffe\\anaconda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\jeffe\\anaconda\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'modelData.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "import csv # for reading the csv file\n",
    "import sys # for max integer num in forward stepwise feature selection\n",
    "import pandas as pd # uses dataframes from pandas\n",
    "import numpy as np # used for arrays\n",
    "from sklearn.ensemble import RandomForestClassifier #  for random forests\n",
    "from sklearn import svm # used for creating mortality models --> Support Vector Machine algorithm\n",
    "from sklearn.neighbors import KNeighborsClassifier # for KNN algorithm\n",
    "from sklearn.linear_model import LogisticRegression # for logistic regression algorithm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import metrics # for accuracy calculation\n",
    "from sklearn.ensemble import RandomForestClassifier # used for creating FSS score predictors --> Random Forest algorithm\n",
    "from sklearn.preprocessing import LabelEncoder # for converting the strs to ints\n",
    "import statistics # used for calculating standard deviation\n",
    "from sklearn.metrics import hinge_loss # used to calculating the hinge loss\n",
    "from sklearn.model_selection import KFold # for implementing k-folds\n",
    "import matplotlib.pyplot as plt # used for plotting the graphs\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import MinMaxScaler # used to allow SVM to run faster\n",
    "\n",
    "\n",
    "# FUNCTIONS:\n",
    "\n",
    "# creates the confusion matrix array by calculating the true and false positives and negatives\n",
    "def create_conf_matrix(y_preds, y_reals):\n",
    "\tTP = 0\n",
    "\tFN = 0\n",
    "\tFP = 0\n",
    "\tTN = 0\n",
    "\tfalsePos = []\n",
    "\tfalseNeg = []\n",
    "\n",
    "\tfor i in range(len(y_preds)):\n",
    "\t\tpred_val = y_preds[i]\n",
    "\t\ttest_val = y_reals[i]\n",
    "\n",
    "\t\tif test_val == 1 and pred_val == 1:\n",
    "\t\t\tTP += 1\n",
    "\t\tif test_val == 1 and pred_val == 0:\n",
    "\t\t\tFN += 1\n",
    "\t\t\tfalseNeg.append(i + 1)\n",
    "\t\tif test_val == 0 and pred_val == 1:\n",
    "\t\t\tFP += 1\n",
    "\t\t\tfalsePos.append(i + 1)\n",
    "\t\tif test_val == 0 and pred_val == 0:\n",
    "\t\t\tTN += 1\n",
    "\n",
    "\t# print(falsePos)\n",
    "\t# print(falseNeg)\n",
    "\treturn [TP, FN, FP, TN]\n",
    "\n",
    "# calculates the accuracy of mortality model results\n",
    "def accuracy(matrix):\n",
    "\tTP = matrix[0]\n",
    "\tTN = matrix[3]\n",
    "\tacc = (TP + TN) / (matrix[0] + matrix[1] + matrix[2] + matrix[3])\n",
    "\treturn acc\n",
    "\n",
    "# calculates the sensitivity of mortality model results\n",
    "def sensitivity(matrix):\n",
    "\tTP = matrix[0]\n",
    "\tFN = matrix[1]\n",
    "\tsens = TP / (TP + FN)\n",
    "\treturn sens\n",
    "\n",
    "# calculates the specificity of mortality model results\n",
    "def specificity(matrix):\n",
    "\tTN = matrix[3]\n",
    "\tFP = matrix[2]\n",
    "\tspec = TN / (TN + FP)\n",
    "\treturn spec\n",
    "\n",
    "\n",
    "# MAIN:\n",
    "\n",
    "dataset = np.array(pd.read_csv('modelData.csv'))\n",
    "target_data = dataset[:, 5] # UPDATE\n",
    "num_entries = len(dataset)\n",
    "\n",
    "labels = [\"ID\"]\n",
    "classes = [\"0\", \"1\"]\n",
    "\n",
    "\n",
    "kfold = KFold(n_splits = 10, shuffle = True, random_state = 100) # creates 10-fold splits\n",
    "\n",
    "final_truths = []\n",
    "final_preds1 = []\n",
    "final_preds2 = []\n",
    "final_preds3 = []\n",
    "final_preds4 = []\n",
    "# final_preds5 = []\n",
    "\n",
    "proba_preds1 = []\n",
    "proba_preds2 = []\n",
    "proba_preds3 = []\n",
    "proba_preds4 = []\n",
    "# proba_preds5 = []\n",
    "\n",
    "for train_index, test_index in kfold.split(dataset):\n",
    "\tx_train, x_test = dataset[train_index], dataset[test_index]\n",
    "\ty_train, y_test = target_data[train_index], target_data[test_index]\n",
    "\n",
    "\n",
    "\tclassifier1 = RandomForestClassifier(max_depth = 6, min_samples_leaf = 3, min_samples_split = 10, class_weight = 'balanced', bootstrap = False, max_features = \"auto\", random_state = 100)\n",
    "\tclassifier2 = svm.SVC(kernel = 'linear', random_state = 100)\n",
    "\tclassifier2Prob = svm.SVC(kernel = 'linear', random_state = 100, probability = True)\n",
    "\tclassifier3 = LogisticRegression(random_state = 100)\n",
    "\tclassifier4 = KNeighborsClassifier(n_neighbors = 2, weights = 'distance')\n",
    "\t# classifier5 = MLPClassifier(random_state = 100)\n",
    "\tprint(\"Models Created . . .\")\n",
    "\n",
    "\tscaling = MinMaxScaler(feature_range = (-1,1)).fit(x_train)\n",
    "\tx_trainSVM = scaling.transform(x_train)\n",
    "\tx_testSVM = scaling.transform(x_test)\n",
    "\n",
    "\tclassifier1.fit(x_train, y_train.ravel())\n",
    "\tclassifier2.fit(x_trainSVM, y_train.ravel())\n",
    "\tclassifier2Prob.fit(x_trainSVM, y_train.ravel())\n",
    "\tclassifier3.fit(x_train, y_train.ravel())\n",
    "\tclassifier4.fit(x_train, y_train.ravel())\n",
    "\t# classifier5.fit(x_train, y_train.ravel())\n",
    "\tprint(\"Models Trained\")\n",
    "\n",
    "\ty_pred1 = classifier1.predict(x_test)\n",
    "\ty_pred2 = classifier2.predict(x_testSVM)\n",
    "\ty_pred3 = classifier3.predict(x_test)\n",
    "\ty_pred4 = classifier4.predict(x_test)\n",
    "\t# y_pred5 = classifier5.predict(x_test)\n",
    "\tprint(\"Models Tested - Normal\")\n",
    "\n",
    "\ty_proba_pred1 = classifier1.predict_proba(x_test)[:,1]\n",
    "\ty_proba_pred2 = classifier2Prob.predict_proba(x_testSVM)[:,1]\n",
    "\ty_proba_pred3 = classifier3.predict_proba(x_test)[:,1]\n",
    "\ty_proba_pred4 = classifier4.predict_proba(x_test)[:,1]\n",
    "\t# y_proba_pred5 = classifier5.predict_proba(x_test)[:,1]\n",
    "\tprint(\"Models Tested - Probability\")\n",
    "\n",
    "\tfor i in range(len(x_test)):\n",
    "\t\tfinal_preds1.append(y_pred1[i])\n",
    "\t\tfinal_preds2.append(y_pred2[i])\n",
    "\t\tfinal_preds3.append(y_pred3[i])\n",
    "\t\tfinal_preds4.append(y_pred4[i])\n",
    "\t\t# final_preds5.append(y_pred5[i])\n",
    "\n",
    "\t\tproba_preds1.append(y_proba_pred1[i])\n",
    "\t\tproba_preds2.append(y_proba_pred2[i])\n",
    "\t\tproba_preds3.append(y_proba_pred3[i])\n",
    "\t\tproba_preds4.append(y_proba_pred4[i])\n",
    "\t\t# proba_preds5.append(y_proba_pred5[i])\n",
    "\n",
    "\t\tfinal_truths.append(y_test[i])\n",
    "\n",
    "\n",
    "\n",
    "# creates ROC curve and calculates AUROC\n",
    "fpr1, tpr1, thresholds1 = metrics.roc_curve(final_truths, proba_preds1)\n",
    "fpr2, tpr2, thresholds1 = metrics.roc_curve(final_truths, proba_preds2)\n",
    "fpr3, tpr3, thresholds1 = metrics.roc_curve(final_truths, proba_preds3)\n",
    "fpr4, tpr4, thresholds1 = metrics.roc_curve(final_truths, proba_preds4)\n",
    "# fpr5, tpr5, thresholds1 = metrics.roc_curve(final_truths, proba_preds5)\n",
    "\n",
    "auc1 = metrics.roc_auc_score(final_truths, final_preds1)\n",
    "auc2 = metrics.roc_auc_score(final_truths, final_preds2)\n",
    "auc3 = metrics.roc_auc_score(final_truths, final_preds3)\n",
    "auc4 = metrics.roc_auc_score(final_truths, final_preds4)\n",
    "# auc5 = metrics.roc_auc_score(final_truths, final_preds5)\n",
    "\n",
    "plt.plot(fpr1, tpr1, label = '%s (area = %0.2f)' % ('Random Forest', auc1))\n",
    "plt.plot(fpr2, tpr2, label = '%s (area = %0.2f)' % ('Support Vector Machine', auc2))\n",
    "plt.plot(fpr3, tpr3, label = '%s (area = %0.2f)' % ('Logistic Regression', auc3))\n",
    "plt.plot(fpr4, tpr4, label = '%s (area = %0.2f)' % ('K-Nearest Neighbors', auc4))\n",
    "# plt.plot(fpr5, tpr5, label = '%s ROC (area = %0.2f)' % ('Multi-Layer Perceptron', auc5))\n",
    "\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "plt.title('Receiver Operating Characteristic Curves for Various Models')\n",
    "plt.legend(loc = \"lower right\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# fig, axes = plt.subplots(nrows = 1, ncols = 1, figsize = (60, 15), dpi = 400)\n",
    "# tree.plot_tree(classifier.estimators_[0], feature_names = labels, class_names = classes, filled = True, impurity = False, precision = 1, fontsize = 10)\n",
    "# fig.savefig('decisionTree.png')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
